## TSCEÂ DemoÂ ğŸ§ âš¡  
*Twoâ€‘StepÂ ContextualÂ Enrichment in 120Â lines â€” for OpenAI **and**Â AzureÂ OpenAI*

---

### TableÂ ofÂ Contents
1. [What is TSCE?](#what-is-tsce)
2. [Repo Highlights](#repo-highlights)
3. [Prerequisites](#prerequisites)
4. [Installation](#installation)
5. [Configuration](#configuration)
6. [QuickÂ Start](#quick-start)
7. [Usage Examples](#usage-examples)
8. [How TSCE Works](#how-tsce-works)
9. [Benchmarks & Expected Wins](#benchmarks--expected-wins)
10. [Troubleshooting](#troubleshooting)
11. [Extending the Demo](#extending-the-demo)
12. [Contributing](#contributing)
13. [License](#license)

---

### What is TSCE?Â <a name="what-is-tsce"></a>

**Twoâ€‘StepÂ ContextualÂ Enrichment (TSCE)** is a dropâ€‘in prompt strategy that:

1. **PhaseÂ 1 â€”Â HyperdimensionalÂ Anchor**  
   Generates a rich latent scaffold (highâ€‘temperature, lowÂ topâ€‘p) from the user prompt.  
2. **PhaseÂ 2 â€”Â Focused Generation**  
   Prepends that anchor as hidden context, forcing the model to answer while locked to a narrower, more reliable semantic subâ€‘space.

Result:  
*Â â‡£Â Hallucinations, â‡£Â instruction slips, â‡£Â formatting errors*  
with zero fineâ€‘tuning and only one extra API call.

---

### Repo HighlightsÂ <a name="repo-highlights"></a>

| File | Purpose |
|------|---------|
| `tsce_demo.py` | Singleâ€‘file demo: runs baseline **vs**Â TSCE, prints both answers, saves `report.json`. |
| `.env.example` | Copy to `.env`; fill in your keys / endpoints. |
| `requirements.txt` | Minimal deps (`pythonâ€‘dotenv`, `requests`, `tiktoken`). |
| `LICENSE` | MITÂ â€”Â use it anywhere. |

*Works with vanilla **OpenAI Cloud** **or** **AzureÂ OpenAI** â€” autoâ€‘detected via envâ€‘vars.*

---

### PrerequisitesÂ <a name="prerequisites"></a>

* PythonÂ 3.8Â +
* An OpenAI API key **or** AzureÂ OpenAI deployment key
* Git & (optionally) virtualenv

---

### InstallationÂ <a name="installation"></a>

```bash
git clone https://github.com/<yourâ€‘username>/tsce-demo.git
cd tsce-demo
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env         # then open .env and paste your keys
```

---

### ConfigurationÂ <a name="configuration"></a>

#### OpenAIÂ Cloud

```env
OPENAI_API_KEY=sk-********************************
# optional
OPENAI_ENDPOINT=https://api.openai.com/v1/chat/completions
MODEL_NAME=gpt-3.5-turbo
```

#### AzureÂ OpenAI

```env
OPENAI_API_TYPE=azure
AZURE_OPENAI_ENDPOINT=https://<resource>.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=gpt-4o           # your deployment name
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_KEY=<azure-key>             # or reuse OPENAI_API_KEY
```

*Leave unused keys blank.*

---

### QuickÂ StartÂ <a name="quick-start"></a>

```bash
python tsce_demo.py "How many r's are in strrawberry?"
```

Sample output:

```
Prompt : How many r's are in strrawberry?

Baseline answer
---------------- There are 2 r's in the wordâ€¦

TSCE answer
----------- The word "strrawberry" contains 4 r's.

Report saved â†’ report.json
```

---

### UsageÂ ExamplesÂ <a name="usage-examples"></a>

```bash
python tsce_demo.py "Rewrite this sentence without any em-dashes â€” can you?"
python tsce_demo.py "Generate a SQL query that counts users per country."
python tsce_demo.py "Explain quantum tunnelling to a 10â€‘yearâ€‘old in 3 bullet points."
```

`report.json` includes token counts and the hidden anchor for postâ€‘hoc analysis.

---

### HowÂ TSCEÂ WorksÂ <a name="how-tsce-works"></a>

```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   prompt â†’ â”‚ PhaseÂ 1     â”‚â”€ anchor_draft â”€â”
            â”‚  (tempÂ 1.0) â”‚                â–¼
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚ PhaseÂ 2     â”‚â†’ final answer
                                   â”‚ (tempÂ 0.01) â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **Hyperdimensional Anchor Prompt**  
  `Generate a semantic hyperdimensional anchor in the latent vector space launching from this initial singleâ€‘dimensional vector: <prompt>`
* PhaseÂ 1 uses **high temperature / tiny topâ€‘p** â†’ rich, quirky latent text.  
* PhaseÂ 2 uses **low temperature** with the anchor prepended â†’ tight, deterministic answer space.

---

### Benchmarks &Â ExpectedÂ WinsÂ <a name="benchmarks--expected-wins"></a>

| Task | Baseline error rate | TSCE error rate | Notes |
|------|--------------------|-----------------|-------|
| Count letters in misspelt word (`"strrawberry"`) | 10Â % | **â‰¤Â 0Â %** | Tokenisation bug fixed |
| Remove emâ€‘dash constraint | 50Â % | **<Â 6Â %** | Style compliance |
| SQL query generation (toy DB) | ~30Â % wrong columns/data type mismatch | **<Â 5Â %** | Anchor encodes schema facets |

*(Numbers from 100â€‘prompt sample; YMMV.)*

---

### TroubleshootingÂ <a name="troubleshooting"></a>

| Symptom | Fix |
|---------|-----|
| `401 Unauthorized` | Wrong or expired key; ensure the key matches the endpoint type. |
| Hangs >Â 2Â min | Slow model; tweak `timeout` in `_chat()` or lower temperature. |
| `ValueError: model not found` | Set `MODEL_NAME` (OpenAI) **or** `AZURE_OPENAI_DEPLOYMENT` (Azure) correctly. |
| Anchor leaks to user | Verify PhaseÂ 2 system message starts with `Hyperdimensional anchor:\n` and low temp. |

---

### ExtendingÂ theÂ DemoÂ <a name="extending-the-demo"></a>

* **Batch runner** â€” loop over a prompt list, save aggregate CSV.  
* **Visualization** â€” embed tâ€‘SNE plot code from the whiteâ€‘paper (convex hulls, arrows).  
* **Guardâ€‘rails** â€” add a selfâ€‘critique third pass for highâ€‘risk domains.  
* **Streamlit UI** â€” dropâ€‘in interactive playground (ask â†’ anchor â†’ answer).  

Pull requests welcome!

---

### ContributingÂ <a name="contributing"></a>

1. Fork the repo  
2. `git checkout -b feature/my-feature`  
3. Commit & push  
4. Open a PR

Please keep new code under MIT license and add a line to `README.md` if you extend functionality.

---

### LicenseÂ <a name="license"></a>

This project is licensed under the **MIT License** â€” free for commercial or private use.  See [LICENSE](./LICENSE) for full text.

---

*Happy anchoring!* ğŸš€
